```{r, include=FALSE}
#---
#title: "Chapter 3 data analysis"
#author: "Antti Kaihovaara"
#date: "November 17, 2018"
#description: "Chapter 3 data"
#Data : "https://archive.ics.uci.edu/ml/datasets/Student+Performance"
#---
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Exercise 2

```{r, include=FALSE}

library(knitr)
library(ggplot2)
library(dplyr)
library(tidyr)
```

##Data


The data we use in this exercise comes from two Portuguese schools (secondary education). The 35 variables in the data include information for example on students' demographics, social background, school success, motivation and free time. In this exercise we use the data to study the associations between students' alcohol consumption and different student characteristics.

You can see the list of the variables below and read more about the data from here: https://archive.ics.uci.edu/ml/datasets/Student+Performance


```{r, include=TRUE}
chapter3analysis <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt", sep=",", header=TRUE) 

colnames(chapter3analysis)
```

```{r, include=FALSE}
str(chapter3analysis)
dim (chapter3analysis)
glimpse (chapter3analysis)
```

##Hypotheses

Alcohol is a hell of a drug. In this exercise we assume that those who consume lots of alcohol are more likely to come from poorer households, do worse in school and have lower studying motivation than average. We form the following four hypotheses:

1. Alcohol consumption is negative correlated with study time (studytime). Those who study more, drink less and and those who study less, drink more. 

2. Students who have more past class failures drink more (failures). Even though we can not test causal inference with our data, we make the assumption that alcohol consumption is likely to cause class failures rather than the other way around.

3. Students who want to take higher education drink less than average since they are more busy studying (higher).

4. Mother's education is negatively correlated with alcohol consumption (Medu).
 

#Graphical illustrations of the associations

Next we study graphically the associations between high use of alcohol and our chosen explanatory variables using boxplots, barplots and crosstabs. 

It seems that high use of alcohol is associated with less study time as was was expected. 

Same applies to alcohol use and past class failures - it seems that those who consume a lotof alcohol are more likely to have past class failures. 

Almost all students are motivated to get higher education, which makes it difficult to distinguish the link between alcohol consumption and motivation. The descriptive graphs and crosstab, however, imply that among those few who are not interested in higher education, alcohol consumption might be more common.

Interestingly, mother's education does not seem to have a significant association with high use of alcohol.


## 1. Alcohol use and study time
```{r, include=TRUE}


g1 <- ggplot(chapter3analysis, aes(x = high_use, y = studytime))

g1 + geom_boxplot() + ggtitle("Study time by alcohol consumption") + ylab("study time") + xlab("high consumption")

gg1 <-ggplot(data=chapter3analysis, aes(x=studytime, y=high_use)) +
  geom_bar(stat="identity")
gg1

table(high_use = chapter3analysis$high_use, studytime = chapter3analysis$studytime)

boxplot(chapter3analysis$studytime, chapter3analysis$failures)

```




## 2. Alcohol use and study and past class failures

```{r, include=TRUE}


g2 <- ggplot(chapter3analysis, aes(x = high_use, y = failures))

g2 + geom_boxplot() + ggtitle("Past failures by alcohol consumption") + ylab("number of past class failures") + xlab("high consumption")

gg2 <-ggplot(data=chapter3analysis, aes(x=failures, y=high_use)) +
  geom_bar(stat="identity")
gg2

table(high_use = chapter3analysis$high_use, failures = chapter3analysis$failures)

```
## 3. Alcohol use and willingness to get higher education

```{r, include=TRUE}
g3 <- ggplot(chapter3analysis, aes(x = high_use, y = higher))

g3 + geom_boxplot() + ggtitle("Willingness to get higher education by alcohol consumption") + ylab("wants to take higher education") + xlab("high consumption")

gg3 <-ggplot(data=chapter3analysis, aes(x=higher, y=high_use)) +
  geom_bar(stat="identity")
gg3

table(high_use = chapter3analysis$high_use, higher= chapter3analysis$higher)
```


## 4. Alcohol use and mother's education
```{r, include=TRUE}
g4 <- ggplot(chapter3analysis, aes(x = high_use, y = Medu))

g4 + geom_boxplot() + ggtitle("Mother's education by alcohol consumption") + ylab("Mother's education") + xlab("high consumption")

gg4 <-ggplot(data=chapter3analysis, aes(x=Medu, y=high_use)) +
  geom_bar(stat="identity")
gg4

table(high_use = chapter3analysis$high_use, Medu = chapter3analysis$Medu)

```

#Logistic regression model

The graphical illustrations suggested that we could perhaps reject the null hypothesis in our three first hypotheses. However, before umping to conclusions, let's run a logistic regression model to see whether there is statistically significant association between the variables. 

The regression table below shows that we might have been a bit too hasty with our analysis. The direction of the coefficients studytime, failures and higher do support our initial hypotheses, but only the coefficient on study time is statistically significant (failures is also significant at the 90 % confidence level).

We can reject the null hypothesis only in hypothesis 1, but based on these results, we can argue that hypotheses 2 and 3 are not totally far-fetched.


```{r, include=TRUE}

model1 <- glm(high_use ~ studytime + failures + higher + Medu, data = chapter3analysis, family = "binomial")

summary(model1)

coef(model1)
```






```{r, include=TRUE}

Oddsratios <- coef(model1) %>% exp

CI <- confint.default(model1) %>% exp

cbind(Oddsratios, CI)
```

The confidence intervals of the odd ratio for studytime do not include 1, which confirms us that the coefficient is statistically significant.

The odds ratio for one unit change in study time is about 0.579 (holding the other predictors constant at certain value). As the odds ratio is below 1, we are looking at a negative relationship between study time and alcohol consumption. Using the formula for probability from odds ratios we can calculate the probabilities of being a high user at each study level. 

P=Odds ratio/1+Odds ratio - P(being a high user) 
1-(0.5786451/(1+0.5786451)) = 0.6334546

```{r, include=TRUE}
1-(0.5786451/(1+0.5786451))
```

The formula above tells us that at one unit rise in study time means about 63 % probability of being a high user in comparison to lower category in study time. As the the categories are not identical, this is difficult to translate into hours.

#Predictive power of the model

Next, we look at how well our model is able to predict whether a student is a high user of alcohol or not. It seems that our model is capabable of prediciting the outcome about 7 times out of 10. While being far from perfcect, this is a reasonable outcome when we consider the fact that modelling was done without theory and we did not even try to tackle the omitted variable bias. Simple guessing would have found the right outcome 5 times out of 10, so with the right tools we were able to improve this rate substantially.


```{r, include=TRUE}



probabilities <- predict(model1, type = "response")

chapter3analysis <- mutate(chapter3analysis, probability = probabilities)

chapter3analysis <- mutate(chapter3analysis, prediction = probability > 0.5)

select(chapter3analysis, studytime, high_use, probability, prediction) %>% tail(10)

table(high_use = chapter3analysis$high_use, prediction = chapter3analysis$prediction)

g <- ggplot(chapter3analysis, aes(x = probability, y = high_use, col = prediction))

g + geom_point()

table(high_use = chapter3analysis$high_use, prediction = chapter3analysis$prediction) %>% prop.table %>% addmargins
```

#Cross-validation

Finally, we cross-validate the data by calculating the proportion of correctly classified obsrvations. This method allows us to predict how well our model is generalizable to an independent data set.

In our model, the proportion of incorrectly classified observations seems to be about 0.293, which means that for a new data set our model would be able to predict ovet 70 % of the values correctly.

```{r, include=TRUE}


loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

 
loss_func(class = chapter3analysis$high_use, prob = chapter3analysis$probability)






